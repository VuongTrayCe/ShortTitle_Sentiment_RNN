{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac00ca05-83d1-431e-bfde-714ecfcdcb33",
   "metadata": {},
   "source": [
    "# import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6695f9e-ba33-47ad-86d4-88b7737b8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from classes import SentimentDataset\n",
    "import torch.optim as optim\n",
    "load_path = 'sentiment_data_loader.pth' # Đảm bảo đường dẫn này chính xác\n",
    "loaded_data = torch.load(load_path)\n",
    "batch_size = loaded_data.get('batch_size', 32)\n",
    "train_loader = loaded_data.get('train_loader')\n",
    "test_loader = loaded_data.get('test_loader')\n",
    "vocab = loaded_data.get('vocab')\n",
    "vocab_size = loaded_data.get('vocab_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c21ec55-0092-4d23-809f-d50c31c004a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7452e7e2-fe1f-4c72-9fc1-6b8b1b762b35",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "067c4337-bca1-4970-aff2-f3973b39b50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Phul luc B: model.py\n",
    "import torch.nn as nn\n",
    "import torchtext.vocab as tvocab\n",
    "import numpy as np\n",
    "\n",
    "# --- Helper function to load GloVe embeddings ---\n",
    "def load_glove_embeddings(glove_path, vocab, embedding_dim):\n",
    "    \"\"\"\n",
    "    Loads GloVe embeddings for words found in the vocabulary.\n",
    "\n",
    "    Args:\n",
    "        glove_path (str): Name of the GloVe vectors (e.g., 'glove.6B.100d').\n",
    "                          Make sure you have downloaded these or torchtext can download them.\n",
    "        vocab (dict): The vocabulary mapping words to indices.\n",
    "        embedding_dim (int): The dimension of the GloVe embeddings.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The embedding matrix.\n",
    "    \"\"\"\n",
    "    print(f\"Loading GloVe vectors: {glove_path}...\")\n",
    "    # Tải GloVe vectors sử dụng torchtext\n",
    "    # Lần đầu chạy có thể mất thời gian để tải file GloVe\n",
    "    try:\n",
    "        glove = tvocab.GloVe(name=glove_path.split('.')[1], # e.g., '6B'\n",
    "                             dim=embedding_dim,            # e.g., 100\n",
    "                             cache='.vector_cache')        # Thư mục lưu cache\n",
    "        print(\"GloVe vectors loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading GloVe vectors: {e}\")\n",
    "        print(\"Please ensure the GloVe files are available or can be downloaded.\")\n",
    "        print(\"You might need to install torchtext: pip install torchtext\")\n",
    "        # Hoặc tải thủ công từ: https://nlp.stanford.edu/projects/glove/\n",
    "        # và giải nén vào thư mục .vector_cache\n",
    "        raise e # Dừng chương trình nếu không tải được GloVe\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "    # Khởi tạo ma trận embedding với giá trị ngẫu nhiên nhỏ\n",
    "    embeddings = np.random.uniform(-0.25, 0.25, (vocab_size, embedding_dim))\n",
    "    embeddings[vocab['<PAD>']] = np.zeros(embedding_dim) # Vector 0 cho PAD\n",
    "\n",
    "    # Điền vào ma trận embedding bằng vector GloVe nếu từ có trong GloVe\n",
    "    loaded_count = 0\n",
    "    for word, idx in vocab.items():\n",
    "        if word in glove.stoi: # stoi: string-to-index mapping trong GloVe object\n",
    "\n",
    "            embeddings[idx] = glove.vectors[glove.stoi[word]].numpy()\n",
    "            loaded_count += 1\n",
    "        # else: để lại giá trị khởi tạo ngẫu nhiên (hoặc có thể gán vector <UNK> nếu muốn)\n",
    "\n",
    "    print(f\"Loaded {loaded_count} vectors from GloVe out of {vocab_size} vocab size.\")\n",
    "    return torch.tensor(embeddings, dtype=torch.float)\n",
    "# --------------------------------------------------\n",
    "#pretrained_embeddings = load_glove_embeddings('glove.6B.100d',vocab,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cbcd36f-074f-49b0-83d9-2b726f606ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self,vocab, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
    "                 pad_idx, pretrained=False, glove_path='glove.6B.100d'): # Thêm vocab và glove_path\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = pad_idx # Lấy index của PAD token\n",
    "\n",
    "        # --- Khởi tạo embedding layer ---\n",
    "        if pretrained:\n",
    "            print(\"Using pre-trained GloVe embeddings.\")\n",
    "            # Tải trọng số GloVe\n",
    "            pretrained_embeddings = load_glove_embeddings(glove_path, vocab, embedding_dim)\n",
    "            # Tạo lớp Embedding từ trọng số đã tải\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                pretrained_embeddings,\n",
    "                freeze=False, # Cho phép fine-tuning embedding nếu muốn (False)\n",
    "                padding_idx=self.padding_idx\n",
    "            )\n",
    "        else:\n",
    "            print(\"Training embeddings from scratch.\")\n",
    "            # Khởi tạo embedding ngẫu nhiên\n",
    "            self.embedding = nn.Embedding(\n",
    "                num_embeddings=vocab_size,\n",
    "                embedding_dim=embedding_dim,\n",
    "                padding_idx=self.padding_idx\n",
    "            )\n",
    "\n",
    "        # --- Khởi tạo khối RNN layer ---\n",
    "        # [Sinh viên bổ sung: dùng nn.RNN với batch_first=True]\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            bidirectional = True,\n",
    "            num_layers=1, # Giữ đơn giản với 1 lớp RNN\n",
    "            batch_first=True, # Quan trọng: input/output có dạng (batch, seq, feature)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # --- Khởi tạo tầng Dense để dự đoán 3 nhãn ---\n",
    "        # [Sinh viên bổ sung: dùng nn.Linear, nhận hidden state từ RNN]\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=hidden_dim, # Input là hidden state cuối cùng của RNN\n",
    "            out_features=output_dim # Output là số lớp cảm xúc (3)\n",
    "        )\n",
    "        # --- Hết phần bổ sung Dense ---\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text shape: (batch_size, seq_len)\n",
    "\n",
    "        # --- Chuyển text thành embedding ---\n",
    "        # [Sinh viên bổ sung]\n",
    "        # embedded shape: (batch_size, seq_len, embedding_dim)\n",
    "        embedded = self.embedding(text)\n",
    "        # --- Hết phần bổ sung embedding forward ---\n",
    "\n",
    "        # --- Đưa qua khối RNN để lẩy hidden state cuối ---\n",
    "        # [Sinh viên bổ sung]\n",
    "        # output shape: (batch_size, seq_len, hidden_dim)\n",
    "        # hidden shape: (num_layers, batch_size, hidden_dim) -> (1, batch_size, hidden_dim)\n",
    "        rnn_output, hidden = self.rnn(embedded)\n",
    "        #_, (hidden, _) = self.rnn(embedded)\n",
    "        # Lấy hidden state cuối cùng của lớp RNN duy nhất\n",
    "        # hidden.squeeze(0) loại bỏ chiều num_layers (vì = 1)\n",
    "        # last_hidden shape: (batch_size, hidden_dim)\n",
    "        #last_hidden = hidden.squeeze(0)\n",
    "        last_hidden = hidden[-1] \n",
    "        # --- Hết phần bổ sung RNN forward ---\n",
    "\n",
    "        # --- Đưa hidden state qua tầng Dense để dự đoán 3 nhãn ---\n",
    "        # [Sinh viên bổ sung]\n",
    "        # predictions shape: (batch_size, output_dim)\n",
    "        last_hidden = self.dropout(last_hidden)  # <-- thêm dòng này\n",
    "\n",
    "        predictions = self.fc(last_hidden)\n",
    "        # --- Hết phần bổ sung Dense forward ---\n",
    "\n",
    "        # [Sinh viên bổ sung: trả về kết quả dự đoán]\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823fda6-797f-4d36-9f6b-cbf0c5e863b7",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e422c91b-cad7-4c51-8f23-87dd5b8f004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "embedding_dim = 100 # Kích thước vector embedding\n",
    "hidden_dim = 128    # Kích thước lớp ẩn RNN\n",
    "output_dim = 3\n",
    "pad_idx = vocab[\"<PAD>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e090296f-2a80-4957-a8fc-7761b1c9cc62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-trained GloVe embeddings.\n",
      "Loading GloVe vectors: glove.6B.100d...\n",
      "GloVe vectors loaded successfully.\n",
      "Loaded 537 vectors from GloVe out of 5000 vocab size.\n",
      "Training embeddings from scratch.\n"
     ]
    }
   ],
   "source": [
    "model_glove= RNNModel(vocab,vocab_size, embedding_dim, hidden_dim, output_dim,pad_idx, pretrained=True,glove_path='glove.6B.100d')\n",
    "model_scratch= RNNModel(vocab,vocab_size, embedding_dim, hidden_dim, output_dim,pad_idx, pretrained=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f4f4a89-5e11-4313-a1d2-b05df6f0793d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e596f7d1-a644-4169-b0aa-432dc09f7ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "--- Starting Training ---\n",
      "Epoch [1/50] - Val Acc: 0.5781, F1: 0.5173\n",
      "Epoch [10/50] - Val Acc: 0.7357, F1: 0.7116\n",
      "Epoch [20/50] - Val Acc: 0.7750, F1: 0.7548\n",
      "Epoch [30/50] - Val Acc: 0.7972, F1: 0.7787\n",
      "Epoch [40/50] - Val Acc: 0.8102, F1: 0.7940\n",
      "Epoch [50/50] - Val Acc: 0.8142, F1: 0.8001\n",
      "\n",
      "✅ Metrics saved to metrics.json\n",
      "Using device: cpu\n",
      "\n",
      "--- Starting Training ---\n",
      "Epoch [1/50] - Val Acc: 0.6903, F1: 0.6754\n",
      "Epoch [10/50] - Val Acc: 0.7669, F1: 0.7502\n",
      "Epoch [20/50] - Val Acc: 0.7747, F1: 0.7568\n",
      "Epoch [30/50] - Val Acc: 0.8040, F1: 0.7880\n",
      "Epoch [40/50] - Val Acc: 0.7929, F1: 0.7768\n",
      "Epoch [50/50] - Val Acc: 0.8006, F1: 0.7871\n",
      "\n",
      "✅ Metrics saved to metrics.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def train_and_evaluate_model(model, train_loader, test_loader, model_name=\"model\", num_epochs=100, learning_rate=0.01, save_path=\"metrics.json\"):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_sequences, batch_labels in train_loader:\n",
    "            batch_sequences = batch_sequences.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_sequences)\n",
    "            loss = criterion(predictions, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_sequences, val_labels in test_loader:\n",
    "                val_sequences = val_sequences.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "\n",
    "                val_predictions = model(val_sequences)\n",
    "                preds_class = torch.argmax(val_predictions, dim=1)\n",
    "\n",
    "                val_preds.extend(preds_class.cpu().numpy())\n",
    "                val_labels_all.extend(val_labels.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels_all, val_preds)\n",
    "        val_f1 = f1_score(val_labels_all, val_preds, average='weighted')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] - Val Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}')\n",
    "\n",
    "    # --- Save metrics to JSON ---\n",
    "    metrics[model_name] = {\n",
    "        \"val_accuracy\": round(val_accuracy, 4),\n",
    "        \"val_f1_score\": round(val_f1, 4)\n",
    "    }\n",
    "\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "    print(f\"\\n✅ Metrics saved to {save_path}\")\n",
    "\n",
    "for (model,model_name) in [(model_glove,\"Model_pretrained\"),(model_scratch,\"Model_scratch\")]:\n",
    "    train_and_evaluate_model(model,train_loader,test_loader,model_name=model_name,num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42977863-5f17-45f3-a6a9-e5a7e981b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# # --- Xác định thiết bị (CPU hoặc GPU nếu có) ---\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using device: {device}\")\n",
    "# learning_rate = 0.01 # Tốc độ học cho SGD\n",
    "# num_epochs = 100\n",
    "# # Khởi tạo mô hình\n",
    "# pad_idx = vocab['<PAD>']\n",
    "# # model = RNNModel(vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx)\n",
    "# #model = model.to(device) # Chuyển model lên device\n",
    "# model = model_glove.to(device)\n",
    "# # --- Bước 3: Định nghĩa Loss và Optimizer ---\n",
    "# criterion = nn.CrossEntropyLoss() # Phù hợp cho bài toán phân loại đa lớp\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate) # Sử dụng SGD theo yêu cầu\n",
    "\n",
    "# # --- Bước 4: Huấn luyện mô hình ---\n",
    "# print(\"\\n--- Starting Training ---\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     epoch_correct = 0\n",
    "#     epoch_total = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for batch_sequences, batch_labels in train_loader:\n",
    "#         batch_sequences = batch_sequences.to(device)\n",
    "#         batch_labels = batch_labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         predictions = model(batch_sequences)\n",
    "#         loss = criterion(predictions, batch_labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()\n",
    "#         preds_class = torch.argmax(predictions, dim=1)\n",
    "#         epoch_correct += (preds_class == batch_labels).sum().item()\n",
    "#         epoch_total += batch_labels.size(0)\n",
    "\n",
    "#         all_preds.extend(preds_class.cpu().numpy())\n",
    "#         all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "#     avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "#     train_accuracy = epoch_correct / epoch_total\n",
    "#     train_f1 = f1_score(all_labels, all_preds, average='weighted')  # or 'macro' if labels are balanced\n",
    "\n",
    "#     # --- Validation ---\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     val_correct = 0\n",
    "#     val_total = 0\n",
    "#     val_preds = []\n",
    "#     val_labels_all = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for val_sequences, val_labels in test_loader:\n",
    "#             val_sequences = val_sequences.to(device)\n",
    "#             val_labels = val_labels.to(device)\n",
    "\n",
    "#             val_predictions = model(val_sequences)\n",
    "#             loss = criterion(val_predictions, val_labels)\n",
    "\n",
    "#             val_loss += loss.item()\n",
    "#             preds_class = torch.argmax(val_predictions, dim=1)\n",
    "#             val_correct += (preds_class == val_labels).sum().item()\n",
    "#             val_total += val_labels.size(0)\n",
    "\n",
    "#             val_preds.extend(preds_class.cpu().numpy())\n",
    "#             val_labels_all.extend(val_labels.cpu().numpy())\n",
    "\n",
    "#     avg_val_loss = val_loss / len(test_loader)\n",
    "#     val_accuracy = val_correct / val_total\n",
    "#     val_f1 = f1_score(val_labels_all, val_preds, average='weighted')  # or 'macro'\n",
    "\n",
    "#     if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "#               f'Train Loss: {avg_epoch_loss:.4f}, Train Acc: {train_accuracy:.4f}, F1: {train_f1:.4f}, '\n",
    "#               f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
